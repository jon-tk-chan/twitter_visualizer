{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee7fb30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functionalize code from experimentation notebook\n",
    "### WORKING: functions for API call to collect tweets, create full tweet df (100 tweets for all )\n",
    "\n",
    "### Date: Feb 9, 2023\n",
    "### Author: Jonathan Chan\n",
    "\n",
    "#to do - MAIN FN, get twitter df w 100 per user, make network graph using filtered rows for each user, \n",
    "\n",
    "### Notes: \n",
    "### TEAM TWITTER HANDLES FROM: https://ourworldindata.org/team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a17f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#General\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#for data collection - webscraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "#handling plots\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure, text\n",
    "\n",
    "#for network creation\n",
    "import networkx as nx\n",
    "\n",
    "#for data collection - tweepy API \n",
    "import tweepy\n",
    "import twitter_credentials #Twitter credentials stored in a file: twitter_credentials.py\n",
    "\n",
    "consumer_key = twitter_credentials.CONSUMER_KEY\n",
    "consumer_secret = twitter_credentials.CONSUMER_SECRET \n",
    "access_token = twitter_credentials.ACCESS_TOKEN\n",
    "access_token_secret = twitter_credentials.ACCESS_SECRET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f284aa4f",
   "metadata": {},
   "source": [
    "Goal: to scrape x number of tweets from each OWID team member and create a) a network map, b) a bigrams \n",
    "\n",
    "The following code will perform the following steps with one or more functions for each\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. Collect OWID team Twitter handles from the website - \n",
    "    output file: owid_team_info.csv (dataframe with columns: name, title, team, twitter_username, other_links\n",
    "    \n",
    "2. Iterate through Twitter handles, collect 250 tweets\n",
    "    Sub function: collect x number of tweets when provided x and twitter handle\n",
    "    output: store as full_team_tweets.csv\n",
    "    assume twitter developer credentials are set up already - imported as twitter_credentials.py\n",
    "    \n",
    "3. Create Network graph images\n",
    "    Subfunction: create a network graph image from a list of users in full_team_tweets.csv\n",
    "       (should work for single user when passing list w single iteM)\n",
    "    Output: image files for each of the twitter users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f6968c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 1 FUNCTION DECLARATION - scrape https://ourworldindata.org/team for OWID team info\n",
    "\n",
    "def get_team_info(in_url=\"https://ourworldindata.org/team\"):\n",
    "    \"\"\"\n",
    "    Returns dataframe containing the info for each OWID team member. \n",
    "        columns:\n",
    "            name: name of team member (str)\n",
    "            title: job position name of team member (str)\n",
    "            twitter_username: twitter username (str - no @ symbol) OR None \n",
    "            other_links: other links found at bottom of each member's section (list of str)\n",
    "            \n",
    "    input: \n",
    "        in_url: string containing the url for the OWID team page\n",
    "    Notes:\n",
    "        - Assume format of in_url matches webpage format of \"https://ourworldindata.org/team\"\n",
    "        as of Feb 6, 2023.\n",
    "        - Unless otherwise indicated, String values are scraped\n",
    "        as they appear on the OWID team site - includes honorifics and capitalization \n",
    "    \"\"\"\n",
    "    response=requests.get(in_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    team_info= []\n",
    "    \n",
    "    #iterate through div element that contain info for each teammate (class name: wp-block-media-text__content)\n",
    "    for tm_div in soup.find_all(class_=\"wp-block-media-text__content\"):\n",
    "\n",
    "        tm_name = tm_div.find(\"h4\").text #name in h4 tag\n",
    "        tm_title = tm_div.find(\"h5\").text #title in h5 tag\n",
    "        tm_twitter=None #variable to store twitter handle as string if it exists\n",
    "        tm_other = [] #list to write non-twitter links to\n",
    "        \n",
    "        for p in tm_div.find_all(\"p\"):\n",
    "            links_list = p.find_all(\"a\", href=True) \n",
    "            for link in links_list:\n",
    "                if 'twitter' in link['href']:\n",
    "                    tm_twitter = link['href'].split(\"/\")[-1] #split by '/' and take last item to get twitter handle\n",
    "                    tm_twitter = tm_twitter.replace(\"@\", \"\") #remove @ symbol - easier to pass to Tweepy module\n",
    "                else:\n",
    "                    tm_other.append(link['href']) #add non-twitter links as 'other_links' column\n",
    "\n",
    "        tm_dict = {\n",
    "            \"name\": tm_name,\n",
    "            \"title\": tm_title,\n",
    "            \"twitter_username\": tm_twitter,\n",
    "            \"other_links\": tm_other\n",
    "        }\n",
    "        team_info.append(tm_dict) \n",
    "    \n",
    "    #MANUAL CHECKS - spot check \n",
    "    assert len(team_info) == 26\n",
    "    assert \"Max Roser\" in team_info[0]['name']\n",
    "    assert \"Jason Crawford\" in team_info[-1]['name']\n",
    "    \n",
    "    return pd.DataFrame(team_info)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "754d39e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 2: return dataframe containing all tweets for users with a twitter account\n",
    "#follows format returned in get_team_info(), get_tweet_info()\n",
    "#SUBFUNCTION - input twtter handle, number of tweets, export raw twitter_data\n",
    "\n",
    "def get_user_tweets(curr_user=\"OurWorldInData\", num_tweets=100):\n",
    "    \"\"\"Returns a list of raw tweet JSON items based on a username\n",
    "    \n",
    "    \n",
    "    Note: \n",
    "        Only tested on num_tweets below 100\n",
    "        REFACTOR: handle queries of tweets more than tweepy limit for a specific\n",
    "        Assume consumer_key, consumer secret are defined before calling function\n",
    "        \n",
    "        please consult developer docs to ensure that your Twitter Developer account\n",
    "        can access the number of tweets you are interested in per month\n",
    "        https://developer.twitter.com/en/support/twitter-api/developer-account\n",
    "    \"\"\"\n",
    "    #authenticate twitter credentials\n",
    "    auth = tweepy.OAuth2AppHandler(consumer_key,\n",
    "                                   consumer_secret\n",
    "                                  )\n",
    "    #add parser to avoid error of non-serializable data: \n",
    "    #https://github.com/tweepy/tweepy/issues/1102\n",
    "    api = tweepy.API(auth, \n",
    "                     parser=tweepy.parsers.JSONParser() \n",
    "                    )\n",
    "    #collect num_tweets\n",
    "    all_tweets = []\n",
    "    tweets_extended = api.user_timeline(screen_name=curr_user, #replaced id=curr_user to remove warning in jupyter notebook\n",
    "                                        tweet_mode='extended', \n",
    "                                        count=num_tweets\n",
    "                                       )\n",
    "    all_tweets = all_tweets + tweets_extended\n",
    "\n",
    "    return all_tweets\n",
    "\n",
    "\n",
    "def get_tweets_df(team_list, tweets_per_tm=5):\n",
    "    \"\"\"Return a dataframe where each row is a tweet from usernames in team_list. Number of tweets collected is defined\n",
    "    as tweet_per_tm (default=100). Final dataframe includes tweet date, id, full text, rt/fav count, hashtag list, and list of \n",
    "    accounts that the tweet interacted with (mentions, replies, retweets) stored as tuples (tweet poster, interacted account)\n",
    "    \n",
    "    input:\n",
    "        team_list: list of twitter handles of team members to collect tweets from(list of str)\n",
    "        tweets_per_tm: number of tweets to collect per team member (int)\n",
    "    \n",
    "    Notes:\n",
    "        -Interactions are stored in raw tweet data collected from get_user_tweets() - in tweet['entities']['user_mentions']\n",
    "        -Retweet and favourite counts only consider the tweet from the team member - does not include retweets/likes on the original tweet\n",
    "        Refactor: nested for loops\n",
    "    \"\"\"\n",
    "    tweet_list = []\n",
    "    all_ints = []\n",
    "    for team_member in team_list:\n",
    "        curr_tweet_count = 0 #counts the number of tweets actually collected\n",
    "        tm_tweets = get_user_tweets(team_member, tweets_per_tm)\n",
    "        for tweet in tm_tweets:\n",
    "            tweet_ints=[]   \n",
    "            user_id = tweet['user']['id_str']\n",
    "            user_name = tweet['user']['screen_name']\n",
    "            interacted_names = [x['screen_name']for x in tweet['entities']['user_mentions']]\n",
    "            interacted_ids = [x['id_str'] for x in tweet['entities']['user_mentions']]\n",
    "            #loop through interacted_names to get tuple of each team member and who they interacted with from this tweet\n",
    "            for interacted in interacted_names:\n",
    "                int_tuple = tuple((user_name, interacted))\n",
    "                tweet_ints.append(int_tuple)\n",
    "                all_ints.append(int_tuple)\n",
    "            #Write raw values from tweet data, and write interaction tuple list in interected_tuples\n",
    "            tweet_dict = {\n",
    "                \"tweet_date\": tweet['created_at'],\n",
    "                \"tweet_id\": tweet['id_str'],\n",
    "                \"full_text\": tweet['full_text'],\n",
    "                \"retweet_count\": tweet['retweet_count'],\n",
    "                \"fav_count\": tweet['favorite_count'],\n",
    "                \"hashtags\": tweet['entities']['hashtags'],\n",
    "                \"user_id\": tweet['user']['id_str'], \n",
    "                \"user_name\": tweet['user']['screen_name'],\n",
    "                \"interacted_tuples\": tweet_ints\n",
    "            }\n",
    "            tweet_list.append(tweet_dict)\n",
    "            curr_tweet_count += 1\n",
    "        print(\"TWEETS COLLECTED FROM {}: {}\".format(team_member, str(curr_tweet_count)))    \n",
    "    return pd.DataFrame(tweet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3ab9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "### STEP 3 FUNCTION - function to create network graphs in matplotlib \n",
    "def create_nx_graph(in_df):\n",
    "    \"\"\"Returns a network graph showing what accounds that users in in_df['user_name'] interacted with on Twitter\n",
    "    input:\n",
    "        in_df: dataframe that includes any users in in_df['user_name'] to make graph of interactions for\n",
    "    Notes:\n",
    "    - Orange will be used for any nodes (twitter accounts) that are part of the OWID team, even if they are an interacted account\n",
    "    instead of a use that get_user_tweets was called on\n",
    "    \n",
    "    \"\"\"\n",
    "    graph = nx.Graph()\n",
    "    plot_title = \"Twitter Interactions for username: \" + \", \".join(in_df['user_name'].unique().tolist())\n",
    "    all_interactions = []\n",
    "    for i, row, in in_df.iterrows():\n",
    "        if len(row['interacted_tuples']) > 0:\n",
    "            for interaction in row['interacted_tuples']:\n",
    "                all_interactions.append(interaction)\n",
    "                graph.add_edge(interaction[0], interaction[1])\n",
    "    #get the degree for each node, then get the values\n",
    "    deg = nx.degree(graph)\n",
    "    degree_values = [v for k, v in deg]\n",
    "    node_size = [v * 100 for v in degree_values] #multiply by 100 to show properly \n",
    "    position = nx.fruchterman_reingold_layout(graph)\n",
    "    color_map = []\n",
    "    for node in graph:\n",
    "        if node in tweets_df['user_name'].unique():\n",
    "            color_map.append('#dda63a')\n",
    "        else:\n",
    "            color_map.append('#26bde2')\n",
    "\n",
    "    fig = plt.figure(3,figsize=(30,30))\n",
    "    plt.title(plot_title,fontdict={'fontsize':29})\n",
    "    nx.draw_networkx(graph, pos=position, node_color=color_map,\n",
    "                     with_labels=True, node_size=node_size,\n",
    "            font_weight='bold')\n",
    "    plt.close()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "251a98de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved team_df to filename: output/team_info.csv\n"
     ]
    }
   ],
   "source": [
    "#STEP 1 - scrape team info from team page using get_team_info()\n",
    "#declare lists to show team members with/without twitter account \n",
    "\n",
    "team_df_filename = \"output/team_info.csv\"\n",
    "team_df = get_team_info()\n",
    "\n",
    "#Get list of accounts that have twitter, do not have twitter\n",
    "team_twittered = [x for x in team_df['twitter_username'] if x]\n",
    "team_twitterless = [x['name'] for i,x in team_df.iterrows() if not x['twitter_username']]\n",
    "\n",
    "team_df.to_csv(team_df_filename)\n",
    "print(\"Saved team_df to filename:\", team_df_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "039ff4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWEETS COLLECTED FROM MaxCRoser: 100\n",
      "TWEETS COLLECTED FROM eortizospina: 100\n",
      "TWEETS COLLECTED FROM _HannahRitchie: 99\n",
      "TWEETS COLLECTED FROM redouad: 100\n",
      "TWEETS COLLECTED FROM larsyencken: 100\n",
      "TWEETS COLLECTED FROM mathisonian: 100\n",
      "TWEETS COLLECTED FROM nat_ahuja: 100\n",
      "TWEETS COLLECTED FROM parriagadap: 100\n",
      "TWEETS COLLECTED FROM danyx23: 100\n",
      "TWEETS COLLECTED FROM salonium: 65\n",
      "TWEETS COLLECTED FROM MarcelGerber9: 100\n",
      "TWEETS COLLECTED FROM charliegiattino: 99\n",
      "TWEETS COLLECTED FROM JoeHasell: 100\n",
      "TWEETS COLLECTED FROM bbherre: 100\n",
      "TWEETS COLLECTED FROM bnjmacdonald: 100\n",
      "TWEETS COLLECTED FROM lucasrodesg: 100\n",
      "TWEETS COLLECTED FROM mallika_snyder: 65\n",
      "TWEETS COLLECTED FROM f_spooner: 98\n",
      "TWEETS COLLECTED FROM jasoncrawford: 100\n",
      "Saved tweets_df to filename: output/team_info.csv\n"
     ]
    }
   ],
   "source": [
    "#STEP 2 - get tweets from Twitter API, save to tweets dataframe\n",
    "tweets_df_filename = \"output/full_team_tweets.csv\"\n",
    "tweets_df = get_tweets_df(team_twittered, 100)\n",
    "tweets_df.to_csv(tweets_df_filename)\n",
    "print(\"Saved tweets_df to filename:\", team_df_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2146a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED IMAGE: output/images/plot_00_MaxCRoser.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_01_EOrtizOspina.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_02__HannahRitchie.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_03_redouad.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_04_larsyencken.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_05_mathisonian.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_06_nat_ahuja.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_07_parriagadap.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_08_DanyX23.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_09_salonium.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_10_MarcelGerber9.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_11_charliegiattino.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_12_JoeHasell.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_13_bbherre.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_14_bnjmacdonald.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_15_lucasrodesg.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_16_mallika_snyder.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_17_f_spooner.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_18_jasoncrawford.png\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "##STEP 3 - rite network graph images - loop through each name in tweets_df, \n",
    "#create a network graph image for that users interactions, \n",
    "#save to outputs/images\n",
    "\n",
    "fig_list = []\n",
    "export_folder = \"output/images/\"\n",
    "for i, team_member in enumerate(tweets_df['user_name'].unique()):\n",
    "    filtered_df = tweets_df.loc[tweets_df['user_name']==team_member]\n",
    "    tm_fig = create_nx_graph(filtered_df)\n",
    "    fig_list.append(tm_fig)\n",
    "    \n",
    "for i, team_member in enumerate(tweets_df['user_name'].unique()):\n",
    "    fig = fig_list[i]\n",
    "    if len(str(i)) < 2:\n",
    "        out_name = export_folder + \"plot_0\" + str(i) + \"_\" + team_member + \".png\"\n",
    "    else:\n",
    "        out_name = export_folder + \"plot_\" + str(i) + \"_\" + team_member + \".png\"\n",
    "    fig.savefig(out_name)\n",
    "    print(\"SAVED IMAGE:\", out_name)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3515e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO TWITTER AVAILABLE:  ['Matthieu Bergel', 'Marwa Boukarim', 'Natalie Reynolds-Garcia', 'Valerie Rogers Muigai', 'Dr. Pablo Rosado', 'Ike Saunders', 'Mojmir Vinkler']\n"
     ]
    }
   ],
   "source": [
    "#Print out names of members that were not included in analysis\n",
    "#do not have twitter handle that was scrapable on teams page: https://ourworldindata.org/team\n",
    "\n",
    "print(\"NO TWITTER AVAILABLE: \", team_twitterless)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
