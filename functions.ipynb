{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee7fb30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functionalize code from experimentation notebook\n",
    "### WORKING: functions for API call to collect tweets, create full tweet df (100 tweets for all )\n",
    "\n",
    "### Date: Feb 9, 2023\n",
    "### Author: Jonathan Chan\n",
    "\n",
    "#to do - MAIN FN, get twitter df w 100 per user, make network graph using filtered rows for each user, \n",
    "\n",
    "### Notes: \n",
    "### TEAM TWITTER HANDLES FROM: https://ourworldindata.org/team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8a17f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#General\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#for data collection - webscraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "#handling plots\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure, text\n",
    "\n",
    "#for network creation\n",
    "import networkx as nx\n",
    "\n",
    "#for data collection - tweepy API \n",
    "import tweepy\n",
    "import twitter_credentials #Twitter credentials stored in a file: twitter_credentials.py\n",
    "\n",
    "consumer_key = twitter_credentials.CONSUMER_KEY\n",
    "consumer_secret = twitter_credentials.CONSUMER_SECRET \n",
    "access_token = twitter_credentials.ACCESS_TOKEN\n",
    "access_token_secret = twitter_credentials.ACCESS_SECRET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f284aa4f",
   "metadata": {},
   "source": [
    "Goal: to scrape x number of tweets from each OWID team member and create a) a network map, b) a bigrams \n",
    "\n",
    "The following code will perform the following steps with one or more functions for each\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. Collect OWID team Twitter handles from the website - \n",
    "    output file: owid_team_info.csv (dataframe with columns: name, title, team, twitter_username, other_links\n",
    "    \n",
    "2. Iterate through Twitter handles, collect 250 tweets\n",
    "    Sub function: collect x number of tweets when provided x and twitter handle\n",
    "    output: store as full_team_tweets.csv\n",
    "    assume twitter developer credentials are set up already - imported as twitter_credentials.py\n",
    "    \n",
    "3. Create Network graph images\n",
    "    Subfunction: create a network graph image from a list of users in full_team_tweets.csv\n",
    "       (should work for single user when passing list w single iteM)\n",
    "    Output: image files for each of the twitter users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f6968c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 1:\n",
    "\n",
    "def get_team_info(in_url=\"https://ourworldindata.org/team\"):\n",
    "    \"\"\"\n",
    "    Returns dataframe containing the info for each OWID team member. \n",
    "        columns:\n",
    "            name: name of team member (str)\n",
    "            title: job position name of team member (str)\n",
    "            twitter_username: twitter username (str - no @ symbol) OR None \n",
    "            other_links: other links found at bottom of each member's section (list of str)\n",
    "            \n",
    "    input: \n",
    "        in_url: string containing the url for the OWID team page\n",
    "    Notes:\n",
    "        - Assume format of in_url matches webpage format of \"https://ourworldindata.org/team\"\n",
    "        as of Feb 6, 2023.\n",
    "        - Unless otherwise indicated, String values are scraped\n",
    "        as they appear on the OWID team site - includes honorifics and capitalization \n",
    "    \"\"\"\n",
    "    response=requests.get(in_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    team_info= []\n",
    "    \n",
    "    #iterate through div element that contain info for each teammate (class name: wp-block-media-text__content)\n",
    "    for tm_div in soup.find_all(class_=\"wp-block-media-text__content\"):\n",
    "\n",
    "        tm_name = tm_div.find(\"h4\").text #name in h4 tag\n",
    "        tm_title = tm_div.find(\"h5\").text #title in h5 tag\n",
    "        tm_twitter=None #variable to store twitter handle as string if it exists\n",
    "        tm_other = [] #list to write non-twitter links to\n",
    "        \n",
    "        for p in tm_div.find_all(\"p\"):\n",
    "            links_list = p.find_all(\"a\", href=True) \n",
    "            for link in links_list:\n",
    "                if 'twitter' in link['href']:\n",
    "                    tm_twitter = link['href'].split(\"/\")[-1] #split by '/' and take last item to get twitter handle\n",
    "                    tm_twitter = tm_twitter.replace(\"@\", \"\") #remove @ symbol - easier to pass to Tweepy module\n",
    "                else:\n",
    "                    tm_other.append(link['href']) #add non-twitter links as 'other_links' column\n",
    "\n",
    "        tm_dict = {\n",
    "            \"name\": tm_name,\n",
    "            \"title\": tm_title,\n",
    "            \"twitter_username\": tm_twitter,\n",
    "            \"other_links\": tm_other\n",
    "        }\n",
    "        team_info.append(tm_dict) \n",
    "    \n",
    "    #MANUAL CHECKS - spot check \n",
    "    assert len(team_info) == 26\n",
    "    assert \"Max Roser\" in team_info[0]['name']\n",
    "    assert \"Jason Crawford\" in team_info[-1]['name']\n",
    "    \n",
    "    return pd.DataFrame(team_info)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "251a98de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>twitter_username</th>\n",
       "      <th>other_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dr. Max Roser</td>\n",
       "      <td>Founder and Director</td>\n",
       "      <td>MaxCRoser</td>\n",
       "      <td>[https://ourworldindata.org/history-of-our-wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Esteban Ortiz-Ospina</td>\n",
       "      <td>Head of Strategy and Operations</td>\n",
       "      <td>eortizospina</td>\n",
       "      <td>[https://global-change-data-lab.org/, mailto:e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. Hannah Ritchie</td>\n",
       "      <td>Deputy Editor and Science Outreach Lead</td>\n",
       "      <td>_HannahRitchie</td>\n",
       "      <td>[mailto:hannah@ourworldindata.org]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Edouard Mathieu</td>\n",
       "      <td>Head of Data and Research</td>\n",
       "      <td>redouad</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr. Lars Yencken</td>\n",
       "      <td>Head of Engineering</td>\n",
       "      <td>larsyencken</td>\n",
       "      <td>[mailto:lars@ourworldindata.org]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name                                    title  \\\n",
       "0             Dr. Max Roser                     Founder and Director   \n",
       "1  Dr. Esteban Ortiz-Ospina          Head of Strategy and Operations   \n",
       "2        Dr. Hannah Ritchie  Deputy Editor and Science Outreach Lead   \n",
       "3           Edouard Mathieu                Head of Data and Research   \n",
       "4          Dr. Lars Yencken                      Head of Engineering   \n",
       "\n",
       "  twitter_username                                        other_links  \n",
       "0        MaxCRoser  [https://ourworldindata.org/history-of-our-wor...  \n",
       "1     eortizospina  [https://global-change-data-lab.org/, mailto:e...  \n",
       "2   _HannahRitchie                 [mailto:hannah@ourworldindata.org]  \n",
       "3          redouad                                                 []  \n",
       "4      larsyencken                   [mailto:lars@ourworldindata.org]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://ourworldindata.org/team\"\n",
    "# team_df = get_team_info(url)\n",
    "team_df = get_team_info()\n",
    "team_df.head()\n",
    "\n",
    "# team_df.to_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "754d39e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 2: connect to API, intake team_df, \n",
    "#return json containing all tweets, as well as list of no twitter data available \n",
    "\n",
    "#SUBFUNCTION - input twtter handle, number of tweets\n",
    "#FUNCTION - creates the JSON \n",
    "\n",
    "def get_user_tweets(curr_user=\"OurWorldInData\", num_tweets=100):\n",
    "    \"\"\"Returns a list of raw tweet JSON items based on a username\n",
    "    \n",
    "    \n",
    "    Note: \n",
    "        REFACTOR: handle queries of tweets more than tweepy limit for a specific\n",
    "        Assume consumer_key, consumer secret are defined before calling function\n",
    "        \n",
    "        please consult developer docs to ensure that your Twitter Developer account\n",
    "        can access the number of tweets you are interested in per month\n",
    "        https://developer.twitter.com/en/support/twitter-api/developer-account\n",
    "    \"\"\"\n",
    "    #authenticate twitter credentials\n",
    "    auth = tweepy.OAuth2AppHandler(\n",
    "    consumer_key, consumer_secret\n",
    "    )\n",
    "    #add parser to avoid error of non-serializable data: \n",
    "    #https://github.com/tweepy/tweepy/issues/1102\n",
    "    api = tweepy.API(auth, \n",
    "                     parser=tweepy.parsers.JSONParser() \n",
    "        )\n",
    "    \n",
    "    #collect num_tweets\n",
    "    all_tweets = []\n",
    "    tweets_extended = api.user_timeline(\n",
    "                                        screen_name=curr_user, #replaced id=curr_user to remove warning in jupyter notebook\n",
    "                                        tweet_mode='extended', \n",
    "                                        count=num_tweets)\n",
    "    all_tweets = all_tweets + tweets_extended\n",
    "#     print(len(all_tweets))\n",
    "#     print(\"COLLECTED: {} TWEETS FROM {}\".format(str(num_tweets), username))\n",
    "    return all_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e615358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_tweets=get_user_tweets('MaxCRoser', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02809a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_tweets[-3]['entities']['hashtags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "324418a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_df(team_list, tweets_per_tm=5):\n",
    "    \"\"\"Return a dataframe where each row is a tweet from usernames in team_list. Number of tweets collected is defined\n",
    "    as tweet_per_tm (default=100). Final dataframe includes tweet date, id, full text, rt/fav count, hashtag list, and list of \n",
    "    accounts that the tweet interacted with (mentions, replies, retweets) stored as tuples (tweet poster, interacted account)\n",
    "    \n",
    "    input:\n",
    "        team_list: list of twitter handles of team members to collect tweets from(list of str)\n",
    "        tweets_per_tm: number of tweets to collect per team member (int)\n",
    "    \n",
    "    Notes:\n",
    "        -Interactions are stored in raw tweet data collected from get_user_tweets() - in tweet['entities']['user_mentions']\n",
    "        -Retweet and favourite counts only consider the tweet from the team member - does not include retweets/likes on the original tweet\n",
    "        Refactor: nested for loops\n",
    "    \"\"\"\n",
    "    tweet_list = []\n",
    "    all_ints = []\n",
    "#     print(\"TEAM_LIST\",team_list)\n",
    "    for team_member in team_list:\n",
    "#         print(\"TM TO SCRAPE:\", team_member)\n",
    "        curr_tweet_count = 0 #counts the number of tweets actually collected\n",
    "        tm_tweets = get_user_tweets(team_member, tweets_per_tm)\n",
    "        for tweet in tm_tweets:\n",
    "            tweet_ints=[]\n",
    "            tweet_date = tweet['created_at']\n",
    "            tweet_id = tweet['id_str'] #id of ACTUAL TWEET\n",
    "            tweet_text= tweet['full_text']\n",
    "            tweet_rts= tweet['retweet_count']\n",
    "            tweet_favs= tweet['favorite_count']\n",
    "            tweet_hts = tweet['entities']['hashtags']\n",
    "            \n",
    "            user_id = tweet['user']['id_str']\n",
    "            user_name = tweet['user']['screen_name']\n",
    "\n",
    "            interacted_names = [x['screen_name']for x in tweet['entities']['user_mentions']]\n",
    "            interacted_ids = [x['id_str'] for x in tweet['entities']['user_mentions']]\n",
    "            \n",
    "            for interacted in interacted_names:\n",
    "                int_tuple = tuple((user_name, interacted))\n",
    "                tweet_ints.append(int_tuple)\n",
    "                all_ints.append(int_tuple)\n",
    "\n",
    "#             print(\"TEAM MEMBER:\", user_name)\n",
    "#             print(\"TWEET TEXT: \", tweet_text)\n",
    "#             print(\"TWEET INTERACTIONS:\", interacted_names)\n",
    "#             print(\"TOTAL INTERACTIONS: \",interactions)\n",
    "            tweet_dict = {\n",
    "                \"tweet_date\": tweet_date,\n",
    "                \"tweet_id\": tweet_id,\n",
    "                \"full_text\": tweet_text,\n",
    "                \"retweet_count\": tweet_rts,\n",
    "                \"fav_count\": tweet_favs,\n",
    "                \"hashtags\": tweet_hts,\n",
    "                \"user_id\": user_id, \n",
    "                \"user_name\": user_name,\n",
    "                \"interacted_tuples\": tweet_ints\n",
    "            }\n",
    "            tweet_list.append(tweet_dict)\n",
    "            curr_tweet_count += 1\n",
    "#             print(tweet_dict)\n",
    "#             print(\"----\")\n",
    "#         print(\"*****\")\n",
    "#         print(\"PROCESSED:\", team_member, \"(NUM TWEETS: \", str(curr_tweet_count))\n",
    "        print(\"TWEETS COLLECTED FROM {}: {}\".format(team_member, str(curr_tweet_count)))\n",
    "        \n",
    "    return pd.DataFrame(tweet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1917a811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEAM WITH TWITTER:  ['MaxCRoser', 'eortizospina', '_HannahRitchie', 'redouad', 'larsyencken', 'mathisonian', 'nat_ahuja', 'parriagadap', 'danyx23', 'salonium', 'MarcelGerber9', 'charliegiattino', 'JoeHasell', 'bbherre', 'bnjmacdonald', 'lucasrodesg', 'mallika_snyder', 'f_spooner', 'jasoncrawford']\n",
      "TEAM WITHOUT TWITTER:  ['Matthieu Bergel', 'Marwa Boukarim', 'Natalie Reynolds-Garcia', 'Valerie Rogers Muigai', 'Dr. Pablo Rosado', 'Ike Saunders', 'Mojmir Vinkler']\n"
     ]
    }
   ],
   "source": [
    "#Get list of accounts that have twitter\n",
    "team_twittered = [x for x in team_df['twitter_username'] if x]\n",
    "print(\"TEAM WITH TWITTER: \", team_twittered)\n",
    "\n",
    "team_twitterless = [x['name'] for i,x in team_df.iterrows() if not x['twitter_username']]\n",
    "print(\"TEAM WITHOUT TWITTER: \", team_twitterless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "039ff4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWEETS COLLECTED FROM MaxCRoser: 100\n",
      "TWEETS COLLECTED FROM eortizospina: 100\n",
      "TWEETS COLLECTED FROM _HannahRitchie: 99\n",
      "TWEETS COLLECTED FROM redouad: 100\n",
      "TWEETS COLLECTED FROM larsyencken: 100\n",
      "TWEETS COLLECTED FROM mathisonian: 100\n",
      "TWEETS COLLECTED FROM nat_ahuja: 100\n",
      "TWEETS COLLECTED FROM parriagadap: 100\n",
      "TWEETS COLLECTED FROM danyx23: 100\n",
      "TWEETS COLLECTED FROM salonium: 65\n",
      "TWEETS COLLECTED FROM MarcelGerber9: 100\n",
      "TWEETS COLLECTED FROM charliegiattino: 99\n",
      "TWEETS COLLECTED FROM JoeHasell: 100\n",
      "TWEETS COLLECTED FROM bbherre: 100\n",
      "TWEETS COLLECTED FROM bnjmacdonald: 100\n",
      "TWEETS COLLECTED FROM lucasrodesg: 100\n",
      "TWEETS COLLECTED FROM mallika_snyder: 65\n",
      "TWEETS COLLECTED FROM f_spooner: 98\n",
      "TWEETS COLLECTED FROM jasoncrawford: 100\n"
     ]
    }
   ],
   "source": [
    "tweets_df = get_tweets_df(team_twittered, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e1aea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.to_csv(\"full_team_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "224f2275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MaxCRoser' '_HannahRitchie' 'redouad' 'larsyencken' 'mathisonian'\n",
      " 'nat_ahuja']\n",
      "['parriagadap' 'salonium' 'MarcelGerber9' 'charliegiattino' 'JoeHasell'\n",
      " 'bbherre']\n",
      "['bnjmacdonald' 'lucasrodesg' 'mallika_snyder' 'f_spooner' 'jasoncrawford']\n"
     ]
    }
   ],
   "source": [
    "# div_i1=7 #divide network graph into two graphs to ensure readability\n",
    "# div_i2=14\n",
    "# df1 = tweets_df.loc[tweets_df['user_name'].isin(team_twittered[:div_i1])]\n",
    "# df2 = tweets_df.loc[tweets_df['user_name'].isin(team_twittered[div_i1:div_i2])]\n",
    "# df3 = tweets_df.loc[tweets_df['user_name'].isin(team_twittered[div_i2:])]\n",
    "# print(df1['user_name'].unique())\n",
    "# print(df2['user_name'].unique())\n",
    "# print(df3['user_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3ab9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_nx_graph(in_df):\n",
    "    \"\"\"Returns a network graph showing what accounds that users in in_df['user_name'] interacted with on Twitter\n",
    "    \n",
    "    Notes:\n",
    "    - Orange will be used for any nodes (twitter accounts) that are part of the OWID team, even if they are an interacted account\n",
    "    instead of a use that get_user_tweets was called on\n",
    "    \n",
    "    \"\"\"\n",
    "    graph = nx.Graph()\n",
    "    plot_title = \"Twitter Interactions for username: \" + \", \".join(in_df['user_name'].unique().tolist())\n",
    "    all_interactions = []\n",
    "    for i, row, in in_df.iterrows():\n",
    "        if len(row['interacted_tuples']) > 0:\n",
    "            for interaction in row['interacted_tuples']:\n",
    "                all_interactions.append(interaction)\n",
    "                graph.add_edge(interaction[0], interaction[1])\n",
    "    #     print(\"----\")\n",
    "    #get the degree for each node, then get the values\n",
    "    deg = nx.degree(graph)\n",
    "    degree_values = [v for k, v in deg]\n",
    "    node_size = [v * 100 for v in degree_values] #multiply by 100 to show properly \n",
    "    position = nx.fruchterman_reingold_layout(graph)\n",
    "\n",
    "    d = dict\n",
    "    color_map = []\n",
    "    for node in graph:\n",
    "    #     print(node)\n",
    "        if node in tweets_df['user_name'].unique():\n",
    "            color_map.append('#dda63a')\n",
    "        else:\n",
    "            color_map.append('#26bde2')\n",
    "\n",
    "    fig = plt.figure(3,figsize=(30,30))\n",
    "    plt.title(plot_title,fontdict={'fontsize':29})\n",
    "    nx.draw_networkx(graph, pos=position, node_color=color_map,\n",
    "                     with_labels=True, node_size=node_size,\n",
    "            font_weight='bold')\n",
    "    plt.close()\n",
    "    return fig\n",
    "\n",
    "# graph1= create_nx_graph(df1)\n",
    "# graph1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f2146a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_list = []\n",
    "export_folder = \"output/images/\"\n",
    "for i, team_member in enumerate(tweets_df['user_name'].unique()):\n",
    "    filtered_df = tweets_df.loc[tweets_df['user_name']==team_member]\n",
    "    tm_fig = create_nx_graph(filtered_df)\n",
    "#     tm_fig.saveimg(out_name)\n",
    "    fig_list.append(tm_fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8fb0c85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED IMAGE: output/images/plot_00_MaxCRoser.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_01_EOrtizOspina.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_02__HannahRitchie.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_03_redouad.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_04_larsyencken.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_05_mathisonian.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_06_nat_ahuja.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_07_parriagadap.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_08_DanyX23.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_09_salonium.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_10_MarcelGerber9.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_11_charliegiattino.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_12_JoeHasell.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_13_bbherre.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_14_bnjmacdonald.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_15_lucasrodesg.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_16_mallika_snyder.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_17_f_spooner.png\n",
      "----\n",
      "SAVED IMAGE: output/images/plot_18_jasoncrawford.png\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for i, team_member in enumerate(tweets_df['user_name'].unique()):\n",
    "    fig = fig_list[i]\n",
    "    if len(str(i)) < 2:\n",
    "        out_name = export_folder + \"plot_0\" + str(i) + \"_\" + team_member + \".png\"\n",
    "    else:\n",
    "        out_name = export_folder + \"plot_\" + str(i) + \"_\" + team_member + \".png\"\n",
    "    fig.savefig(out_name)\n",
    "    print(\"SAVED IMAGE:\", out_name)\n",
    "    print(\"----\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e3515e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO TWITTER AVAILABLE:  Matthieu Bergel\n",
      "-----\n",
      "NO TWITTER AVAILABLE:  Marwa Boukarim\n",
      "-----\n",
      "NO TWITTER AVAILABLE:  Natalie Reynolds-Garcia\n",
      "-----\n",
      "NO TWITTER AVAILABLE:  Valerie Rogers Muigai\n",
      "-----\n",
      "NO TWITTER AVAILABLE:  Dr. Pablo Rosado\n",
      "-----\n",
      "NO TWITTER AVAILABLE:  Ike Saunders\n",
      "-----\n",
      "NO TWITTER AVAILABLE:  Mojmir Vinkler\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for team_member in team_twitterless:\n",
    "    print(\"NO TWITTER AVAILABLE: \", team_member)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bf85470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph = nx.Graph()\n",
    "\n",
    "# all_interactions=[]\n",
    "# for i, row, in tweets_df.iterrows():\n",
    "#     if len(row['interacted_tuples']) > 0:\n",
    "#         for interaction in row['interacted_tuples']:\n",
    "#             all_interactions.append(interaction)\n",
    "#             graph.add_edge(interaction[0], interaction[1])\n",
    "# #     print(\"----\")\n",
    "# #get the degree for each node, then get the values\n",
    "# deg = nx.degree(graph)\n",
    "# degree_values = [v for k, v in deg]\n",
    "# node_size = [v * 100 for v in degree_values] #multiply by 100 to show properly \n",
    "# position = nx.fruchterman_reingold_layout(graph)\n",
    "\n",
    "# d = dict\n",
    "# color_map = []\n",
    "# for node in graph:\n",
    "# #     print(node)\n",
    "#     if node in tweets_df['user_name'].unique():\n",
    "#         color_map.append('#dda63a')\n",
    "#     else:\n",
    "#         color_map.append('#26bde2')\n",
    "\n",
    "\n",
    "\n",
    "# plt.figure(3,figsize=(24,24))\n",
    "# nx.draw_networkx(graph, pos=position, node_color=color_map,\n",
    "#                  with_labels=True, node_size=node_size,\n",
    "#         font_weight='bold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9f7766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2763965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nx.draw(G, node_color=color_map, with_labels=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca7c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01718518",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d0a199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11033953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OBS\n",
    "\n",
    "# tweets_per_tm=5\n",
    "# graph = nx.Graph()\n",
    "# for team_member in team_df['twitter_username']:\n",
    "#     print(team_member)\n",
    "    \n",
    "#     if team_member:\n",
    "#         print(\"YESS\")\n",
    "#         tm_tweets = get_user_tweets(team_member, tweets_per_tm)\n",
    "#         for tweet in tm_tweets:\n",
    "#             tweet_date = tweet['created_at']\n",
    "#             tweet_id = tweet['id_str'] #id of ACTUAL TWEET\n",
    "#             tweet_text= tweet['full_text']\n",
    "#             user_id = tweet['user']['id_str']\n",
    "#             user_name = tweet['user']['screen_name']\n",
    "\n",
    "#             interacted_names = [x['screen_name']for x in tweet['entities']['user_mentions']]\n",
    "#             interacted_ids = [x['id_str'] for x in tweet['entities']['user_mentions']]\n",
    "# #             print(\"1 TWEET - TEAM MEMBER, USER NAME, INTERACTED NAMES: \", team_member, user_name, interacted_names )\n",
    "#             ### user_name == team_member\n",
    "#             for interacted in interacted_names:\n",
    "#                 graph.add_edge(user_name, interacted, tweet_id = tweet_id)   \n",
    "#     else:\n",
    "#         print(\"NOOOO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a4ee1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_tm_data(in_json='raw_tweets.json',tm_subgroup=['MaxCRoser']):\n",
    "#     \"\"\"Return the nx.graph() containing the interactions of users listed in tm_subgroup\"\"\"\n",
    "#     in_\n",
    "\n",
    "# def create_nx_graph():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c756a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['MaxCRoser'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3fd0d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_json='raw_tweets.json'\n",
    "# with open(in_json) as json_file:\n",
    "#     data=json.load(json_file)\n",
    "# team_filtered = data.keys()\n",
    "# # team_filtered = [\"MaxCRoser\"]\n",
    "# team_filtered\n",
    "\n",
    "# for username in team_filtered:\n",
    "#     tweet_list = data[username]\n",
    "#     print(tweet_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a09c049",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filtered_tweets = []\n",
    "\n",
    "# graph=nx.Graph()\n",
    "# #First loop - extract relevant items from raw json - only for users in filtered \n",
    "# for username in team_filtered:\n",
    "#     tweet_list = data[username]\n",
    "#     print(\"CURRENT TWITTER HANDLE: \", username)\n",
    "#     for tweet in tweets_list:\n",
    "# #         print(tweet.keys())\n",
    "#         tweet_date = tweet['created_at']\n",
    "#         tweet_id = tweet['id_str'] #id of ACTUAL TWEET\n",
    "#         tweet_text= tweet['full_text']\n",
    "#         user_id = tweet['user']['id_str']\n",
    "#         user_name = tweet['user']['screen_name']\n",
    "        \n",
    "#         interacted_names = [x['screen_name']for x in tweet['entities']['user_mentions']]\n",
    "#         interacted_ids = [x['id_str'] for x in tweet['entities']['user_mentions']]\n",
    "        \n",
    "#         for interacted in interacted_names:\n",
    "#             graph.add_edge(username, interacted_name, tweet_id = tweet_id)\n",
    "        \n",
    "#         tweet_dict = {\n",
    "#             \"user_id\": user_id,\n",
    "#             \"user_name\": user_name,\n",
    "#             \"tweet_id\": tweet_id,\n",
    "#             \"tweet_date\": tweet_date,\n",
    "#             \"tweet_text\": tweet_text,\n",
    "#             \"interacted_ids\": interacted_ids,\n",
    "#             \"interacted_names\": interacted_names    \n",
    "#         }\n",
    "#         filtered_tweets.append(tweet_dict)\n",
    "        \n",
    "# print(filtered_tweets[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2882435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e81a5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph = nx.Graph()\n",
    "# #PART 2: for all tweets in filtered_tweets, add an interaction to the nx.graph()\n",
    "# for tweet in filtered_tweets:\n",
    "#     print(tweet.keys())\n",
    "#     user_name = tweet['user_name']\n",
    "#     tweet_id = tweet['tweet_id']\n",
    "#     interacted_ids = tweet['interacted_ids']\n",
    "#     if len(interacted_ids) == 0:\n",
    "#         print(\"     NO INTERACTIONS\")\n",
    "#     else:\n",
    "#         for interacted_name in tweet['interacted_names']:\n",
    "#             print(tuple((user_name, interacted_name)))\n",
    "#     print(\"---\")\n",
    "    \n",
    "    \n",
    "\n",
    "    #CHECK: user_name for some tweets is the user that should be in the interacted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8a1127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d630e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
